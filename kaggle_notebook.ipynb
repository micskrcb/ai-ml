{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 3004,
          "databundleVersionId": 861823,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30746,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "kaggle-notebook",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'digit-recognizer:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F3004%2F861823%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240812%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240812T182821Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D26eb6d6875d44db9a49d48c6e0d760c40a2b2842c70f2724891dc9b5d79aebd5ed6032f9b4bb18b89a0c435e22d1de457701c2835d97fa709de6e6d73e37843939216550d3f52be77d7d3da4230050fd30cb80d1e04b4a0044ee382eb7fb59ca35221a3deffea03ed0b302773da566964a0a4616e382e7158cc0db38f123a0c6f16a61779298259bc4ee5c249071f14c02af6f1cee7152a0dc06ce144326277c5095f18dfcbbe75c99311dc85f6b560b247f1caa2e6a6f654a023da423944374b11fb882e1d89f4199cb7e4f30c52372522856a9a563bd3acb95eb94043d99fe32a09fef8ed6c1bd79395b311e0615f84729349b8c636ac71dac4080bef77cf9'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "4tX1cGQY2VV0"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "88MIe3SK2VV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "d = pd.read_csv('/kaggle/input/digit-recognizer/train.csv')\n",
        "d = np.array(d)\n",
        "m, n = d.shape\n",
        "np.random.shuffle(d)\n",
        "\n",
        "d_dev = d_[0:1000].T\n",
        "Y_dev = d_dev[0]\n",
        "X_dev = d_dev[1:n].T\n",
        "X_dev = X_dev / 255.0\n",
        "\n",
        "d_train = d_[1000:m].T\n",
        "y_train = d_train[0]\n",
        "x_train = d_train[1:n].T\n",
        "x_train = x_train / 255.0\n",
        "_, m_train = x_train.shape\n",
        "\n",
        "class Linear:\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    - input_dim (int): No of input features\n",
        "    - output_dim (int): No of output features\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        self.weights = np.random.randn(input_dim, output_dim) * 0.01\n",
        "        self.bias = np.zeros((1, output_dim))\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        - X (ndarray): Input data\n",
        "\n",
        "        Returns:\n",
        "        - ndarray: Output data\n",
        "        \"\"\"\n",
        "        self.input = X\n",
        "        return np.dot(X, self.weights) + self.bias\n",
        "\n",
        "    def backward(self, g_output):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        - g_output (ndarray): Grad from next layer\n",
        "\n",
        "        Returns:\n",
        "        - ndarray: Grad with respect to input\n",
        "        \"\"\"\n",
        "        g_input = np.dot(g_output, self.weights.T)\n",
        "        self.g_weights = np.dot(self.input.T, g_output)\n",
        "        self.g_bias = np.sum(g_output, axis=0, keepdims=True)\n",
        "        return g_input\n",
        "\n",
        "class ReLU:\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        - X (ndarray): Input data\n",
        "\n",
        "        Returns:\n",
        "        - ndarray: Output after ReLU activation\n",
        "        \"\"\"\n",
        "        self.input = X\n",
        "        return np.maximum(0, X)\n",
        "\n",
        "    def backward(self, g_output):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        - g_output (ndarray): Grad from next layer\n",
        "\n",
        "        Returns:\n",
        "        - ndarray: Grad with respect to input\n",
        "        \"\"\"\n",
        "        g_input = g_output * (self.input > 0)\n",
        "        return g_input\n",
        "\n",
        "class Softmax:\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        - X (ndarray): Input data\n",
        "\n",
        "        Returns:\n",
        "        - ndarray: Output\n",
        "        \"\"\"\n",
        "        exp_values = np.exp(X - np.max(X, axis=1, keepdims=True))\n",
        "        self.output = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, g_output):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        - g_output (ndarray): Grad  from next layer\n",
        "\n",
        "        Returns:\n",
        "        - ndarray: Grad  with respect to input\n",
        "        \"\"\"\n",
        "        return g_output\n",
        "\n",
        "class CrossEntropyLoss:\n",
        "    def forward(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        - y_pred (ndarray): Predicted probabilities\n",
        "        - y_true (ndarray): True labels\n",
        "\n",
        "        Returns:\n",
        "        - float: Loss value\n",
        "        \"\"\"\n",
        "        samples = len(y_pred)\n",
        "        y_pred_clipped = np.clip(y_pred, 1e-12, 1. - 1e-12)\n",
        "        correct_confidences = y_pred_clipped[range(samples), y_true]\n",
        "        return -np.mean(np.log(correct_confidences))\n",
        "\n",
        "    def backward(self, y_pred, y_true):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        - y_pred (ndarray): Predicted probabilities\n",
        "        - y_true (ndarray): True labels\n",
        "\n",
        "        Returns:\n",
        "        - ndarray: Gradient with respect to input\n",
        "        \"\"\"\n",
        "        samples = len(y_pred)\n",
        "        g_ = y_pred\n",
        "        g_[range(samples), y_true] -= 1\n",
        "        return g_ / samples\n",
        "\n",
        "class SGD:\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    - learning_rate (float)\n",
        "    \"\"\"\n",
        "    def __init__(self, learning_rate=0.01):\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def step(self, layers):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        - layers (list): List of model layers to update\n",
        "        \"\"\"\n",
        "        for layer in layers:\n",
        "            if hasattr(layer, 'weights'):\n",
        "                layer.weights -= self.learning_rate * layer.g_weights\n",
        "                layer.bias -= self.learning_rate * layer.g_bias\n",
        "\n",
        "class Model:\n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        self.loss = None\n",
        "        self.optimizer = None\n",
        "\n",
        "    def add_layer(self, layer):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        - layer\n",
        "        \"\"\"\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    def compile(self, loss, optimizer):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        - loss: function\n",
        "        - optimizer: Optimizer instance\n",
        "        \"\"\"\n",
        "        self.loss = loss\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        - X (ndarray): Input data\n",
        "\n",
        "        Returns:\n",
        "        - ndarray: final output\n",
        "        \"\"\"\n",
        "        for layer in self.layers:\n",
        "            X = layer.forward(X)\n",
        "        return X\n",
        "\n",
        "    def backward(self, g_output):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        - g_output (ndarray): Gradient of loss with respect to output\n",
        "        \"\"\"\n",
        "        for layer in reversed(self.layers):\n",
        "            g_output = layer.backward(g_output)\n",
        "\n",
        "    def train(self, X, y, epochs):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        - X (ndarray): Training data\n",
        "        - y (ndarray): True labels\n",
        "        - epochs (int): Number of epochs to train\n",
        "        \"\"\"\n",
        "        for epoch in range(epochs):\n",
        "            y_pred = self.forward(X)\n",
        "            loss_value = self.loss.forward(y_pred, y)\n",
        "            g_output = self.loss.backward(y_pred, y)\n",
        "            self.backward(g_output)\n",
        "            self.optimizer.step(self.layers)\n",
        "            print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss_value:.4f}')\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        - X (ndarray): Input data\n",
        "\n",
        "        Returns:\n",
        "        - ndarray: Predicted output\n",
        "        \"\"\"\n",
        "        return self.forward(X)\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        - X (ndarray): Input data\n",
        "        - y (ndarray): True labels\n",
        "\n",
        "        Returns:\n",
        "        - tuple: Loss value and accuracy\n",
        "        \"\"\"\n",
        "        y_pred = self.predict(X)\n",
        "        loss_value = self.loss.forward(y_pred, y)\n",
        "        accuracy = np.mean(np.argmax(y_pred, axis=1) == y)\n",
        "        print(f'Loss: {loss_value:.4f}, Accuracy: {accuracy:.4f}')\n",
        "        return loss_value, accuracy\n",
        "\n",
        "model = Model()\n",
        "model.add_layer(Linear(784, 128))\n",
        "model.add_layer(ReLU())\n",
        "model.add_layer(Linear(128, 10))\n",
        "model.add_layer(Softmax())\n",
        "\n",
        "loss = CrossEntropyLoss()\n",
        "optimizer = SGD(learning_rate=0.2)\n",
        "model.compile(loss, optimizer)\n",
        "\n",
        "model.train(x_train, y_train, epochs=150)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_dev, Y_dev)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-12T17:58:22.542794Z",
          "iopub.execute_input": "2024-08-12T17:58:22.54334Z",
          "iopub.status.idle": "2024-08-12T18:00:12.41576Z",
          "shell.execute_reply.started": "2024-08-12T17:58:22.543279Z",
          "shell.execute_reply": "2024-08-12T18:00:12.41456Z"
        },
        "trusted": true,
        "id": "9aW8pjx42VV5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}